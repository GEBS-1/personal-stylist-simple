# üé® –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –æ–±—É—á–µ–Ω–∏—é —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π AI –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ç–∏–ª–∏—Å—Ç–∞

## üìã –û–±–∑–æ—Ä

–≠—Ç–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ–º–æ–∂–µ—Ç —Å–æ–∑–¥–∞—Ç—å –∏ –æ–±—É—á–∏—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é AI –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –æ–±—Ä–∞–∑–æ–≤ –æ–¥–µ–∂–¥—ã.

## üéØ –¶–µ–ª–∏ –æ–±—É—á–µ–Ω–∏—è

1. **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—Ä–∞–∑–æ–≤** - —Å–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–Ω—ã—Ö –∫–æ–º–ø–ª–µ–∫—Ç–æ–≤ –æ–¥–µ–∂–¥—ã
2. **–ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è** - —É—á–µ—Ç —Ç–∏–ø–∞ —Ñ–∏–≥—É—Ä—ã, —Ä–∞–∑–º–µ—Ä–æ–≤, –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π
3. **–°—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏** - —Å–æ–≤–µ—Ç—ã –ø–æ —Å–æ—á–µ—Ç–∞–Ω–∏—é —Ü–≤–µ—Ç–æ–≤ –∏ —Å—Ç–∏–ª–µ–π
4. **–¶–µ–Ω–æ–≤–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è** - –ø–æ–¥–±–æ—Ä –ø–æ –±—é–¥–∂–µ—Ç—É

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ä–µ—à–µ–Ω–∏—è

### 1. –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å
```bash
# –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è fine-tuning:
- Llama 2 7B Chat (13GB)
- Mistral 7B Instruct (13GB) 
- Gemma 2B IT (4GB)
- Phi-2 (2.7GB)
```

### 2. –ú–µ—Ç–æ–¥—ã –æ–±—É—á–µ–Ω–∏—è
```bash
# LoRA (Low-Rank Adaptation) - 8GB VRAM
- –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ
- –ú–∞–ª–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
- –•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ

# QLoRA (Quantized LoRA) - 4GB VRAM
- –û–±—É—á–µ–Ω–∏–µ –Ω–∞ CPU
- –≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏
- –ü—Ä–∏–µ–º–ª–µ–º–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ

# Full Fine-tuning - 24GB+ VRAM
- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
- –¢—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ —Ä–µ—Å—É—Ä—Å–æ–≤
```

## üìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö

### 1. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
```json
{
  "instruction": "–°–æ–∑–¥–∞–π –æ–±—Ä–∞–∑ –¥–ª—è –∂–µ–Ω—â–∏–Ω—ã —Å —Ç–∏–ø–æ–º —Ñ–∏–≥—É—Ä—ã hourglass, —Ä–æ—Å—Ç–æ–º 170—Å–º, –æ–±—Ö–≤–∞—Ç–æ–º –≥—Ä—É–¥–∏ 90—Å–º, —Ç–∞–ª–∏–∏ 70—Å–º, –±–µ–¥–µ—Ä 95—Å–º. –°—Ç–∏–ª—å: casual, —Ü–≤–µ—Ç–∞: —Å–∏–Ω–∏–π, –±–µ–ª—ã–π, –ø–æ–≤–æ–¥: –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–π, —Å–µ–∑–æ–Ω: –ª–µ—Ç–æ, –±—é–¥–∂–µ—Ç: —Å—Ä–µ–¥–Ω–∏–π.",
  "input": "",
  "output": "{\n  \"name\": \"–õ–µ—Ç–Ω–∏–π –∫—ç–∂—É–∞–ª\",\n  \"description\": \"–ö–æ–º—Ñ–æ—Ä—Ç–Ω—ã–π –æ–±—Ä–∞–∑ –¥–ª—è –∂–∞—Ä–∫–æ–≥–æ –¥–Ω—è\",\n  \"items\": [\n    {\n      \"category\": \"–í–µ—Ä—Ö\",\n      \"description\": \"–°–≤–æ–±–æ–¥–Ω–∞—è –±–ª—É–∑–∞ –∏–∑ —Ö–ª–æ–ø–∫–∞\",\n      \"colors\": [\"–±–µ–ª—ã–π\", \"–≥–æ–ª—É–±–æ–π\"],\n      \"style\": \"–∫—ç–∂—É–∞–ª\",\n      \"fit\": \"—Å–≤–æ–±–æ–¥–Ω—ã–π\",\n      \"price\": \"2000-4000\"\n    },\n    {\n      \"category\": \"–ù–∏–∑\",\n      \"description\": \"–î–∂–∏–Ω—Å—ã mom-fit\",\n      \"colors\": [\"—Å–∏–Ω–∏–π\"],\n      \"style\": \"–∫—ç–∂—É–∞–ª\",\n      \"fit\": \"–≤—ã—Å–æ–∫–∞—è –ø–æ—Å–∞–¥–∫–∞\",\n      \"price\": \"3000-6000\"\n    }\n  ],\n  \"styleNotes\": \"–ü–æ–¥—á–µ—Ä–∫–∏–≤–∞–µ—Ç —Ç–∞–ª–∏—é, —Å–∫—Ä—ã–≤–∞–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏\",\n  \"colorPalette\": [\"–±–µ–ª—ã–π\", \"–≥–æ–ª—É–±–æ–π\", \"—Å–∏–Ω–∏–π\"],\n  \"totalPrice\": \"5000-10000 ‚ÇΩ\"\n}"
}
```

### 2. –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö
```bash
# 1. –°–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
- –ê–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω—ã—Ö –æ–±—Ä–∞–∑–æ–≤
- –û—Ç–∑—ã–≤—ã –∫–ª–∏–µ–Ω—Ç–æ–≤
- –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

# 2. –ü—É–±–ª–∏—á–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã
- Fashion-MNIST
- DeepFashion
- StyleGAN datasets

# 3. –í–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥
- Pinterest
- Instagram
- –ú–æ–¥–Ω—ã–µ –±–ª–æ–≥–∏
```

### 3. –†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞
```bash
# –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –æ–±—É—á–µ–Ω–∏—è:
- 1000 –ø—Ä–∏–º–µ—Ä–æ–≤ –æ–±—Ä–∞–∑–æ–≤
- 5000 –ø—Ä–∏–º–µ—Ä–æ–≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
- 10000 –ø—Ä–∏–º–µ—Ä–æ–≤ —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Å–æ–≤–µ—Ç–æ–≤

# –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Ä–∞–∑–º–µ—Ä:
- 10000+ –ø—Ä–∏–º–µ—Ä–æ–≤ –æ–±—Ä–∞–∑–æ–≤
- 50000+ –ø—Ä–∏–º–µ—Ä–æ–≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
- 100000+ –ø—Ä–∏–º–µ—Ä–æ–≤ —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Å–æ–≤–µ—Ç–æ–≤
```

## üöÄ –ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è

### 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install torch transformers datasets accelerate
pip install peft bitsandbytes
pip install llama-cpp-python

# –î–ª—è GPU –æ–±—É—á–µ–Ω–∏—è
pip install flash-attn
```

### 2. –°–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è
```python
# train_fashion_model.py
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import LoraConfig, get_peft_model
from datasets import Dataset

def train_fashion_model():
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    model_name = "meta-llama/Llama-2-7b-chat-hf"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(model_name)
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LoRA
    lora_config = LoraConfig(
        r=16,
        lora_alpha=32,
        target_modules=["q_proj", "v_proj"],
        lora_dropout=0.05,
        bias="none",
        task_type="CAUSAL_LM"
    )
    
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ LoRA
    model = get_peft_model(model, lora_config)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    dataset = Dataset.from_json("fashion_dataset.json")
    
    # –û–±—É—á–µ–Ω–∏–µ
    trainer = Trainer(
        model=model,
        train_dataset=dataset,
        tokenizer=tokenizer,
        args=TrainingArguments(
            output_dir="./fashion-model",
            num_train_epochs=3,
            per_device_train_batch_size=4,
            gradient_accumulation_steps=4,
            learning_rate=2e-4,
            warmup_steps=100,
            logging_steps=10,
            save_steps=500
        )
    )
    
    trainer.train()
    trainer.save_model()
```

### 3. –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
```python
# quantize_model.py
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

def quantize_model():
    # –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    model = AutoModelForCausalLM.from_pretrained(
        "./fashion-model",
        torch_dtype=torch.float16,
        device_map="auto"
    )
    
    # –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
    model = torch.quantization.quantize_dynamic(
        model, {torch.nn.Linear}, dtype=torch.qint8
    )
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–≤–∞–Ω—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    model.save_pretrained("./fashion-model-quantized")
```

## üìà –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞

### 1. –ú–µ—Ç—Ä–∏–∫–∏
```python
# evaluation.py
def evaluate_model():
    metrics = {
        "accuracy": 0.85,  # –¢–æ—á–Ω–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        "coherence": 0.78, # –°–≤—è–∑–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞
        "relevance": 0.92, # –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –æ–±—Ä–∞–∑–æ–≤
        "diversity": 0.81  # –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ
    }
    return metrics
```

### 2. A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
```bash
# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é
- –ö–∞—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑–æ–≤
- –°–∫–æ—Ä–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
- –ü–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤
- –£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
```

## üîß –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ

### 1. –ó–∞–º–µ–Ω–∞ OpenAI –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
```typescript
// –í openaiService.ts
import { localAIService } from './localAIService';

// –ó–∞–º–µ–Ω–∞ generateOutfit
async generateOutfit(request: OutfitRequest): Promise<GeneratedOutfit> {
  try {
    // –ü—Ä–æ–±—É–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
    return await localAIService.generateOutfit(request);
  } catch (error) {
    // Fallback –∫ —Å–∏–º—É–ª—è—Ü–∏–∏
    return this.simulateGPTResponse(request);
  }
}
```

### 2. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
```typescript
// model-config.ts
export const modelConfig = {
  modelPath: './models/fashion-stylist.gguf',
  maxTokens: 1000,
  temperature: 0.7,
  contextLength: 4096,
  threads: 4
};
```

## üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å –∏ —Ä–µ—Å—É—Ä—Å—ã

### 1. –û–±—É—á–µ–Ω–∏–µ
```bash
# –û–±–ª–∞—á–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã (Google Colab Pro)
- 1 –º–µ—Å—è—Ü –æ–±—É—á–µ–Ω–∏—è: $50-100
- 100 —á–∞—Å–æ–≤ GPU: $200-500

# –õ–æ–∫–∞–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã
- RTX 4090 (24GB): $1500
- –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: 2-7 –¥–Ω–µ–π
```

### 2. –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
```bash
# –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å–µ—Ä–≤–µ—Ä—É
- CPU: 8+ —è–¥–µ—Ä
- RAM: 16GB+
- Storage: 50GB –¥–ª—è –º–æ–¥–µ–ª–∏

# –°—Ç–æ–∏–º–æ—Å—Ç—å —Ö–æ—Å—Ç–∏–Ω–≥–∞
- VPS —Å GPU: $100-500/–º–µ—Å—è—Ü
- –û–±–ª–∞—á–Ω—ã–µ AI —Å–µ—Ä–≤–∏—Å—ã: $50-200/–º–µ—Å—è—Ü
```

## üéØ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏

### ‚úÖ –ü–ª—é—Å—ã
- **–ö–æ–Ω—Ç—Ä–æ–ª—å –¥–∞–Ω–Ω—ã—Ö** - –ø–æ–ª–Ω–∞—è –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å
- **–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è** - –æ–±—É—á–µ–Ω–∞ –Ω–∞ –º–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- **–ö–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è** - –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –Ω—É–∂–¥—ã
- **–≠–∫–æ–Ω–æ–º–∏—è** - –Ω–µ—Ç –ø–ª–∞—Ç—ã –∑–∞ API
- **–ù–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å** - –Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –≤–Ω–µ—à–Ω–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤

### ‚ùå –ú–∏–Ω—É—Å—ã
- **–°–ª–æ–∂–Ω–æ—Å—Ç—å** - —Ç—Ä–µ–±—É–µ—Ç ML —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã
- **–†–µ—Å—É—Ä—Å—ã** - –Ω—É–∂–Ω—ã –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ –º–æ—â–Ω–æ—Å—Ç–∏
- **–í—Ä–µ–º—è** - –¥–ª–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
- **–ö–∞—á–µ—Å—Ç–≤–æ** - –º–æ–∂–µ—Ç –±—ã—Ç—å —Ö—É–∂–µ GPT-4
- **–ü–æ–¥–¥–µ—Ä–∂–∫–∞** - –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ

## üöÄ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

1. **–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö** - —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –æ–±—Ä–∞–∑–æ–≤
2. **–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏** - Llama 2 –∏–ª–∏ Mistral
3. **–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã** - GPU/–æ–±–ª–∞—á–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã
4. **–û–±—É—á–µ–Ω–∏–µ** - fine-tuning –º–æ–¥–µ–ª–∏
5. **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ** - –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
6. **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è** - –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—é
7. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** - –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

## üìö –ü–æ–ª–µ–∑–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [Hugging Face](https://huggingface.co/) - –º–æ–¥–µ–ª–∏ –∏ –¥–∞—Ç–∞—Å–µ—Ç—ã
- [Llama.cpp](https://github.com/ggerganov/llama.cpp) - –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
- [PEFT](https://github.com/huggingface/peft) - —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
- [Ollama](https://ollama.ai/) - –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏
- [LM Studio](https://lmstudio.ai/) - GUI –¥–ª—è –º–æ–¥–µ–ª–µ–π 